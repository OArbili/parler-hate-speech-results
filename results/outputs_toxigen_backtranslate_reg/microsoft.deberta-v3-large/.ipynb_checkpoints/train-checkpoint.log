max_len: 512
========== fold: 0 training ==========
BackTranslation None
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-large",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1024,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.0615  avg_val_loss: 0.0526  time: 2659s
Epoch 1 - Score: 0.3243  Scores: [0.3242721156094184]
Epoch 1 - Save Best Score: 0.3243 Model
========== fold: 0 training ==========
BackTranslation ['de', 'es', 'fr']
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-large",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1024,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

load ../outputs_toxigen_backtranslate_reg//microsoft.deberta-v3-large/microsoft-deberta-v3-large_fold0_pre.pth
Epoch 1 - avg_train_loss: 0.0267  avg_val_loss: 0.0197  time: 327s
Epoch 1 - Score: 0.1986  Scores: [0.1986095466355043]
Epoch 1 - Save Best Score: 0.1986 Model
Epoch 2 - avg_train_loss: 0.0193  avg_val_loss: 0.0194  time: 328s
Epoch 2 - Score: 0.1972  Scores: [0.19716369976755357]
Epoch 2 - Save Best Score: 0.1972 Model
Epoch 3 - avg_train_loss: 0.0158  avg_val_loss: 0.0186  time: 326s
Epoch 3 - Score: 0.1926  Scores: [0.19264126261443115]
Epoch 3 - Save Best Score: 0.1926 Model
Epoch 4 - avg_train_loss: 0.0119  avg_val_loss: 0.0185  time: 335s
Epoch 4 - Score: 0.1926  Scores: [0.19256059382516447]
Epoch 4 - Save Best Score: 0.1926 Model
Epoch 5 - avg_train_loss: 0.0094  avg_val_loss: 0.0186  time: 336s
Epoch 5 - Score: 0.1930  Scores: [0.1929656772270118]
========== fold: 0 result ==========
Score: 0.1926  Scores: [0.19256059382516447]
========== fold: 1 training ==========
BackTranslation ['de', 'es', 'fr']
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-large",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1024,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

load ../outputs_toxigen_backtranslate_reg//microsoft.deberta-v3-large/microsoft-deberta-v3-large_fold0_pre.pth
Epoch 1 - avg_train_loss: 0.0268  avg_val_loss: 0.0204  time: 328s
Epoch 1 - Score: 0.2018  Scores: [0.20176088730388222]
Epoch 1 - Save Best Score: 0.2018 Model
Epoch 2 - avg_train_loss: 0.0198  avg_val_loss: 0.0239  time: 325s
Epoch 2 - Score: 0.2185  Scores: [0.2185114169727523]
Epoch 3 - avg_train_loss: 0.0150  avg_val_loss: 0.0194  time: 323s
Epoch 3 - Score: 0.1967  Scores: [0.19672584631394427]
Epoch 3 - Save Best Score: 0.1967 Model
