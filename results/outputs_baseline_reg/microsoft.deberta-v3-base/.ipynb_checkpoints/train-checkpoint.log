max_len: 512
========== fold: 0 training ==========
BackTranslation None
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.0295  avg_val_loss: 0.0223  time: 141s
Epoch 1 - Score: 0.2111  Scores: [0.21105634290966233]
Epoch 1 - Save Best Score: 0.2111 Model
Epoch 2 - avg_train_loss: 0.0161  avg_val_loss: 0.0206  time: 141s
Epoch 2 - Score: 0.2029  Scores: [0.20293341810803486]
Epoch 2 - Save Best Score: 0.2029 Model
Epoch 3 - avg_train_loss: 0.0108  avg_val_loss: 0.0217  time: 140s
Epoch 3 - Score: 0.2085  Scores: [0.20851046100668394]
Epoch 4 - avg_train_loss: 0.0062  avg_val_loss: 0.0205  time: 140s
Epoch 4 - Score: 0.2024  Scores: [0.20242179519457848]
Epoch 4 - Save Best Score: 0.2024 Model
Epoch 5 - avg_train_loss: 0.0048  avg_val_loss: 0.0205  time: 142s
Epoch 5 - Score: 0.2026  Scores: [0.20262949487581958]
========== fold: 0 result ==========
Score: 0.2024  Scores: [0.20242179519457848]
========== fold: 1 training ==========
BackTranslation None
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.0341  avg_val_loss: 0.0242  time: 141s
Epoch 1 - Score: 0.2202  Scores: [0.2201870556377109]
Epoch 1 - Save Best Score: 0.2202 Model
Epoch 2 - avg_train_loss: 0.0156  avg_val_loss: 0.0227  time: 142s
Epoch 2 - Score: 0.2132  Scores: [0.21323831300209586]
Epoch 2 - Save Best Score: 0.2132 Model
Epoch 3 - avg_train_loss: 0.0093  avg_val_loss: 0.0211  time: 141s
Epoch 3 - Score: 0.2055  Scores: [0.2054590237174285]
Epoch 3 - Save Best Score: 0.2055 Model
Epoch 4 - avg_train_loss: 0.0061  avg_val_loss: 0.0215  time: 145s
Epoch 4 - Score: 0.2074  Scores: [0.20736538896776197]
Epoch 5 - avg_train_loss: 0.0050  avg_val_loss: 0.0214  time: 146s
Epoch 5 - Score: 0.2068  Scores: [0.20676477972063445]
========== fold: 1 result ==========
Score: 0.2055  Scores: [0.2054590237174285]
========== fold: 2 training ==========
BackTranslation None
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.0293  avg_val_loss: 0.0239  time: 147s
Epoch 1 - Score: 0.2184  Scores: [0.21842220526211178]
Epoch 1 - Save Best Score: 0.2184 Model
Epoch 2 - avg_train_loss: 0.0165  avg_val_loss: 0.0225  time: 142s
Epoch 2 - Score: 0.2122  Scores: [0.21221035423537504]
Epoch 2 - Save Best Score: 0.2122 Model
Epoch 3 - avg_train_loss: 0.0118  avg_val_loss: 0.0223  time: 142s
Epoch 3 - Score: 0.2112  Scores: [0.21116842205274625]
Epoch 3 - Save Best Score: 0.2112 Model
Epoch 4 - avg_train_loss: 0.0072  avg_val_loss: 0.0226  time: 142s
Epoch 4 - Score: 0.2124  Scores: [0.21241488397148015]
Epoch 5 - avg_train_loss: 0.0057  avg_val_loss: 0.0221  time: 141s
Epoch 5 - Score: 0.2104  Scores: [0.21042743309539194]
Epoch 5 - Save Best Score: 0.2104 Model
========== fold: 2 result ==========
Score: 0.2104  Scores: [0.21042743309539194]
========== fold: 3 training ==========
BackTranslation None
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.0294  avg_val_loss: 0.0253  time: 140s
Epoch 1 - Score: 0.2252  Scores: [0.22515709685244237]
Epoch 1 - Save Best Score: 0.2252 Model
Epoch 2 - avg_train_loss: 0.0161  avg_val_loss: 0.0227  time: 140s
Epoch 2 - Score: 0.2128  Scores: [0.21283873842306342]
Epoch 2 - Save Best Score: 0.2128 Model
Epoch 3 - avg_train_loss: 0.0110  avg_val_loss: 0.0229  time: 139s
Epoch 3 - Score: 0.2139  Scores: [0.21388305694030585]
Epoch 4 - avg_train_loss: 0.0064  avg_val_loss: 0.0227  time: 141s
Epoch 4 - Score: 0.2132  Scores: [0.213152739399381]
Epoch 5 - avg_train_loss: 0.0050  avg_val_loss: 0.0227  time: 142s
Epoch 5 - Score: 0.2132  Scores: [0.21323253193508387]
========== fold: 3 result ==========
Score: 0.2128  Scores: [0.21283873842306342]
========== CV ==========
Score: 0.2078  Scores: [0.2078271256639727]
